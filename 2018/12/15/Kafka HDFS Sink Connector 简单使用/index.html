<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="a personal blog"><title>Kafka HDFS Sink Connector 简单使用 | Not determined yet</title><link rel="stylesheet" type="text/css" href="/blog/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/blog/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/blog/favicon.ico"><link rel="apple-touch-icon" href="/blog/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/blog/apple-touch-icon.png"><script src="https://www.googletagmanager.com/gtag/js?id=G-N73FWWZR9G" async></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-N73FWWZR9G');
</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><style type="text/css">
.spoiler {
  display: inline-flex;
}
p.spoiler {
  display: flex;
}
.spoiler a {
  pointer-events: none;
}
.spoiler-blur, .spoiler-blur > * {
  transition: text-shadow .5s ease;
}
.spoiler .spoiler-blur, .spoiler .spoiler-blur > * {
  color: rgba(0, 0, 0, 0);
  background-color: rgba(0, 0, 0, 0);
  text-shadow: 0 0 10px grey;
  cursor: pointer;
}
.spoiler .spoiler-blur:hover, .spoiler .spoiler-blur:hover > * {
  text-shadow: 0 0 5px grey;
}
.spoiler-box, .spoiler-box > * {
  transition: color .5s ease,
  background-color .5s ease;
}
.spoiler .spoiler-box, .spoiler .spoiler-box > * {
  color: black;
  background-color: black;
  text-shadow: none;
}</style><meta name="generator" content="Hexo 6.1.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Kafka HDFS Sink Connector 简单使用</h1><a id="logo" href="/blog/.">Not determined yet</a><p class="description">知其强，守其弱，为天下菜，为天下菜，可以下饭。</p></div><div id="nav-menu"><a class="current" href="/blog/."><i class="fa fa-home"> 首页</i></a><a href="/blog/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/blog/about/"><i class="fa fa-user"> 关于</i></a><a href="/blog/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><div class="alert alert-danger" role="alert"><i class="fa fa-exclamation-triangle warning"> 本文发表的时间过于久远，其中的信息可能已经有所发展或者不再适用于现阶段</i></div><h1 class="post-title">Kafka HDFS Sink Connector 简单使用</h1><div class="post-meta">2018-12-15<span> | </span><span class="category"><a href="/blog/categories/%E6%8A%80%E6%9C%AF/">技术</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 2.7k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 14</span><span class="post-meta-item-text"> 分钟</span></span></span></div><a class="disqus-comment-count" data-disqus-identifier="2018/12/15/Kafka HDFS Sink Connector 简单使用/" href="/blog/2018/12/15/Kafka%20HDFS%20Sink%20Connector%20%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/#disqus_thread"></a><div class="post-content"><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>HDFS Connector允许以各种格式将数据从Kafka topic 导出到HDFS文件。</p>
<h2 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h2><p>本文依赖于<a href="https://counter2015.github.io/2018/12/04/confluent%20kafka%20%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E5%90%AF%E5%8A%A8/">Confluent</a>，<a href="https://counter2015.github.io/2018/12/13/hadoop%20quick%20start/">Hadoop</a>。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">jps</span></span><br><span class="line">85043 QuorumPeerMain</span><br><span class="line">6204 ConnectDistributed</span><br><span class="line">193805 SupportedKafka</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">切换到工作目录</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> /root/bin/confluent</span></span><br></pre></td></tr></table></figure>
<p>需要先启动以上三个服务。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试环境下可以通过Confluent Cli来开发</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">confluent start</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生产环境下，需要根据自己的需要调整启动参数，以下是几个例子</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动zookeeper</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">zkServer.sh start</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动kafka</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="variable">$&#123;CONFLUENT_HOME&#125;</span>/bin/kafka-server-start \</span></span><br><span class="line"><span class="language-bash">-daemon <span class="variable">$&#123;CONFLUENT_HOME&#125;</span>/etc/kafka/server.properties</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动connect</span></span><br><span class="line">KAFKA_HEAP_OPTS=&quot;-Xms1G -Xmx8G&quot; </span><br><span class="line">KAFKA_LOG4J_OPTS=&quot;-Dlog4j.configuration=file:$&#123;CONFLUENT_HOME&#125;/etc/kafka/connect-log4j.properties&quot;  </span><br><span class="line">connect-distributed -daemon  $CONFLUENT_HOME/etc/kafka/connect-distributed.properties</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>在启动Confluent Platform之前，需要先确保Hadoop在本地或远程运行，并且知晓HDFS URL,并在&#x2F;etc&#x2F;hosts中配置域名解析,<code>core-site.xml</code>中的<code>fs.default</code>,本文中为<code>hdfs://mycentos:9000</code></p>
<h2 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h2><p>简单对kafka进行基本操作举几个例子</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 列出当前所有的topic</span><br><span class="line">$ bin/kafka-topics --list --zookeeper node1:2181</span><br><span class="line"></span><br><span class="line"># 创建一个topic</span><br><span class="line">$ bin/kafka-topics --create --zookeeper node1:2181 --topic test-1 --partitions 1 --replication-factor 1</span><br><span class="line"></span><br><span class="line"># 删除一个topic</span><br><span class="line">$ bin/kafka-topics --delete --zookeeper node1:2181 --topic test-1 </span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>WARNING</strong>: topic命名虽然说基本没有什么限制，但是有几点需要注意，合法字符是数字和大小写字母加上下划线<code>_</code>,减号<code>-</code>,点<code>.</code>，topic的长度最好不超过200，因为最大的长度也就240左右。<code>.</code>和<code>_</code>不能同时使用，这会导致很多奇怪的问题，下面举个例子。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 创建topic `test-1`</span><br><span class="line">$ bin/kafka-topics --create --zookeeper node1:2181 --topic test_1 --partitions 1 --replication-factor 1</span><br><span class="line"></span><br><span class="line">WARNING: Due to limitations in metric names, topics with a period (&#x27;.&#x27;) or underscore (&#x27;_&#x27;) could collide. To avoid issues it is best to use either, but not both.</span><br><span class="line">Created topic &quot;test_1&quot;.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 我们尝试建立 `test.1`的topic</span><br><span class="line">$ bin/kafka-topics --create --zookeeper node1:2181 --topic test.1 --partitions 1 --replication-factor 1</span><br><span class="line"></span><br><span class="line">WARNING: Due to limitations in metric names, topics with a period (&#x27;.&#x27;) or underscore (&#x27;_&#x27;) could collide. To avoid issues it is best to use either, but not both.</span><br><span class="line">Error while executing topic command : Topic &#x27;test.1&#x27; collides with existing topics: test_1</span><br><span class="line">[2018-12-04 18:31:42,730] ERROR org.apache.kafka.common.errors.InvalidTopicException: Topic &#x27;hdfs_test.1&#x27; collides with existing topics: hdfs_test_1</span><br><span class="line"> (kafka.admin.TopicCommand$)</span><br></pre></td></tr></table></figure>

<p>构造测试数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/kafka-topics --create --zookeeper node1:2181 --topic test-1 --partitions 1 --replication-factor 1</span></span><br><span class="line">Created topic &quot;test-1&quot;.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">通过控制台随便传入些json格式的数据,最后按Ctrl+C退出</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/kafka-console-producer --broker-list node1:9092 --topic test-1</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&#123;<span class="string">&quot;type&quot;</span>:<span class="string">&quot;type1&quot;</span>, <span class="string">&quot;time&quot;</span>:<span class="string">&quot;2332&quot;</span>, <span class="string">&quot;msg&quot;</span>:<span class="string">&quot;sadf 12124&quot;</span>&#125;</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&#123;<span class="string">&quot;type&quot;</span>:<span class="string">&quot;type2&quot;</span>, <span class="string">&quot;time&quot;</span>:<span class="string">&quot;2333&quot;</span>, <span class="string">&quot;msg&quot;</span>:<span class="string">&quot;sadf 12324&quot;</span>&#125;</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&#123;<span class="string">&quot;type&quot;</span>:<span class="string">&quot;type1&quot;</span>, <span class="string">&quot;time&quot;</span>:<span class="string">&quot;2333&quot;</span>, <span class="string">&quot;msg&quot;</span>:<span class="string">&quot;sadf 123124&quot;</span>&#125;</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&#123;<span class="string">&quot;type&quot;</span>:<span class="string">&quot;type3&quot;</span>, <span class="string">&quot;time&quot;</span>:<span class="string">&quot;2334&quot;</span>, <span class="string">&quot;msg&quot;</span>:<span class="string">&quot;sadf 1231&quot;</span>&#125;</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以在输入的同时另外打开一个终端观察是否数据正常传入</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/kafka-console-consumer --bootstrap-server node1:9092 --topic test-1 --from-beginning</span></span><br><span class="line">&#123;&quot;type&quot;:&quot;type1&quot;, &quot;time&quot;:&quot;2332&quot;, &quot;msg&quot;:&quot;sadf 12124&quot;&#125;</span><br><span class="line">&#123;&quot;type&quot;:&quot;type2&quot;, &quot;time&quot;:&quot;2333&quot;, &quot;msg&quot;:&quot;sadf 12324&quot;&#125;</span><br><span class="line">&#123;&quot;type&quot;:&quot;type1&quot;, &quot;time&quot;:&quot;2333&quot;, &quot;msg&quot;:&quot;sadf 123124&quot;&#125;</span><br><span class="line">&#123;&quot;type&quot;:&quot;type3&quot;, &quot;time&quot;:&quot;2334&quot;, &quot;msg&quot;:&quot;sadf 1231&quot;&#125;</span><br></pre></td></tr></table></figure>
<p>万事具备，只欠connector的配置了。</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>配置文件<code>hdfs-1.json</code></p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfs-sink-1&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;connector.class&quot;</span><span class="punctuation">:</span> <span class="string">&quot;io.confluent.connect.hdfs.HdfsSinkConnector&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tasks.max&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;topics&quot;</span><span class="punctuation">:</span> <span class="string">&quot;test-1&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;hdfs.url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfs://mycentos:9000/tmp/confluent/test1&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;flush.size&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;format.class&quot;</span><span class="punctuation">:</span> <span class="string">&quot;io.confluent.connect.hdfs.json.JsonFormat&quot;</span> </span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Notes: 当前用户需要有在<code>hdfs.url</code>的权限,并实现在hdfs上创建对应目录</p>
</blockquote>
<p>通过REST API上传配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -X POST -H <span class="string">&quot;Content-Type: application/json&quot;</span> --data @hdfs-1.json http://node1:8083/connectors</span></span><br><span class="line">&#123;&quot;name&quot;:&quot;hdfs-sink-1&quot;,&quot;config&quot;:&#123;&quot;connector.class&quot;:&quot;io.confluent.connect.hdfs.HdfsSinkConnector&quot;,&quot;tasks.max&quot;:&quot;1&quot;,&quot;topics&quot;:&quot;test-1&quot;,&quot;hdfs.url&quot;:&quot;hdfs://h28227:9000/tmp/confluent/test1&quot;,&quot;flush.size&quot;:&quot;1&quot;,&quot;format.class&quot;:&quot;io.confluent.connect.hdfs.json.JsonFormat&quot;,&quot;name&quot;:&quot;hdfs-sink-1&quot;&#125;,&quot;tasks&quot;:[],&quot;type&quot;:null&#125;</span><br></pre></td></tr></table></figure>



<h2 id="检验"><a href="#检验" class="headerlink" title="检验"></a>检验</h2><p>可以在hdfs对应目录查看到结果<br>默认情况下，hdfs的存放将topics和logs分开存放在<code>hdfs.url</code>下的对应目录下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hdfs dfs -<span class="built_in">ls</span> /tmp/confluent/test1</span></span><br><span class="line">Found 2 items</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2018-12-06 16:08 /tmp/confluent/test1/logs</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2018-12-06 16:08 /tmp/confluent/test1/topics</span><br></pre></td></tr></table></figure>

<p>我们可以看到数据存放到<code>test-1</code>目录下，而临时文件存放到<code>+tmp</code>目录下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hdfs dfs -<span class="built_in">ls</span> /tmp/confluent/test1/topics</span></span><br><span class="line">Found 3 items</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2018-12-06 16:08 /tmp/confluent/test1/topics/+tmp</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2018-12-06 16:08 /tmp/confluent/test1/topics/test-1</span><br></pre></td></tr></table></figure>

<p>可以看到，这里分了三个区存</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hdfs dfs -<span class="built_in">ls</span> /tmp/confluent/test1/topics/test-1</span></span><br><span class="line">Found 3 items</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2018-12-06 16:08 /tmp/confluent/test1/topics/test-1/partition=0</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2018-12-06 16:08 /tmp/confluent/test1/topics/test-1/partition=1</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2018-12-06 16:08 /tmp/confluent/test1/topics/test-1/partition=2</span><br></pre></td></tr></table></figure>

<p>这和<code>test-1</code>的分区信息有关</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/kafka-topics --zookeeper node1:2181 --describe --topic test-1</span></span><br><span class="line">Topic:test-1	PartitionCount:3	ReplicationFactor:1	Configs:</span><br><span class="line">	Topic: test-1	Partition: 0	Leader: 1004	Replicas: 1004	Isr: 1004</span><br><span class="line">	Topic: test-1	Partition: 1	Leader: 1005	Replicas: 1005	Isr: 1005</span><br><span class="line">	Topic: test-1	Partition: 2	Leader: 1001	Replicas: 1001	Isr: 1001</span><br></pre></td></tr></table></figure>

<p>下载验证hdfs上的文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hdfs dfs -getmerge /tmp/confluent/test1/topics/test-1/* 1</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> 1</span></span><br><span class="line">&#123;&quot;msg&quot;:&quot;sadf 12124&quot;,&quot;time&quot;:&quot;2332&quot;,&quot;type&quot;:&quot;type1&quot;&#125;</span><br><span class="line">&#123;&quot;msg&quot;:&quot;sadf 123124&quot;,&quot;time&quot;:&quot;2333&quot;,&quot;type&quot;:&quot;type1&quot;&#125;</span><br><span class="line">&#123;&quot;msg&quot;:&quot;sadf 1231&quot;,&quot;time&quot;:&quot;2334&quot;,&quot;type&quot;:&quot;type3&quot;&#125;</span><br><span class="line">&#123;&quot;msg&quot;:&quot;sadf 12324&quot;,&quot;time&quot;:&quot;2333&quot;,&quot;type&quot;:&quot;type2&quot;&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hdfs dfs -<span class="built_in">ls</span> /tmp/confluent/test1/topics/test-1/partition=0</span> </span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   3 root supergroup         50 2018-12-06 16:08 /tmp/confluent/test1/topics/test-1/partition=0/test-1+0+0000000000+0000000000.json</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hdfs dfs -<span class="built_in">cat</span> /tmp/confluent/test1/topics/test-1/partition=0/*</span></span><br><span class="line">&#123;&quot;msg&quot;:&quot;sadf 12124&quot;,&quot;time&quot;:&quot;2332&quot;,&quot;type&quot;:&quot;type1&quot;&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hdfs dfs -<span class="built_in">cat</span> /tmp/confluent/test1/topics/test-1/partition=1/*</span></span><br><span class="line">&#123;&quot;msg&quot;:&quot;sadf 123124&quot;,&quot;time&quot;:&quot;2333&quot;,&quot;type&quot;:&quot;type1&quot;&#125;</span><br><span class="line">&#123;&quot;msg&quot;:&quot;sadf 1231&quot;,&quot;time&quot;:&quot;2334&quot;,&quot;type&quot;:&quot;type3&quot;&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hdfs dfs -<span class="built_in">cat</span> /tmp/confluent/test1/topics/test-1/partition=2/*</span></span><br><span class="line">&#123;&quot;msg&quot;:&quot;sadf 12324&quot;,&quot;time&quot;:&quot;2333&quot;,&quot;type&quot;:&quot;type2&quot;&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="使用更多的参数"><a href="#使用更多的参数" class="headerlink" title="使用更多的参数"></a>使用更多的参数</h2><p>默认情况下，存储位置是按照<code>partition</code>来生成路径的，像之前的例子，存放数据的位置为<code>hdfs://&lt;hdfs.url&gt;/topics/&lt;topic-name&gt;/partition=&lt;i&gt;/</code>,可以不可以按数据的时间来存放呢？</p>
<h3 id="按时间存放"><a href="#按时间存放" class="headerlink" title="按时间存放"></a>按时间存放</h3><p>新建一个<code>t3</code>,用<code>kafka-console-consumer</code>传入下面数据并查看</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/kafka-console-consumer --bootstrap-server node1:9092 --from-beginning --topic t3</span></span><br><span class="line">&#123;&quot;f1&quot;:&quot;type1&quot;, &quot;f2&quot;:&quot;2333&quot;, &quot;f3&quot;:&quot;sadf 123124&quot;&#125;</span><br><span class="line">&#123;&quot;f1&quot;:&quot;type3&quot;, &quot;f2&quot;:&quot;2334&quot;, &quot;f3&quot;:&quot;sadf 1231&quot;&#125;</span><br><span class="line">&#123;&quot;f1&quot;:&quot;type1&quot;, &quot;f2&quot;:&quot;2332&quot;, &quot;f3&quot;:&quot;sadf 12124&quot;&#125;</span><br><span class="line">&#123;&quot;f1&quot;:&quot;type2&quot;, &quot;f2&quot;:&quot;2333&quot;, &quot;f3&quot;:&quot;sadf 12324&quot;&#125;</span><br></pre></td></tr></table></figure>





<p>配置文件<code>hdfs-t1.json</code></p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfs-sink-t1&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;connector.class&quot;</span><span class="punctuation">:</span> <span class="string">&quot;io.confluent.connect.hdfs.HdfsSinkConnector&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tasks.max&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;topics&quot;</span><span class="punctuation">:</span> <span class="string">&quot;t3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;hdfs.url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfs://mycentos:9000/tmp/confluent/test3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;flush.size&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;format.class&quot;</span><span class="punctuation">:</span> <span class="string">&quot;io.confluent.connect.hdfs.json.JsonFormat&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;partitioner.class&quot;</span><span class="punctuation">:</span> <span class="string">&quot;io.confluent.connect.storage.partitioner.TimeBasedPartitioner&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;path.format&quot;</span><span class="punctuation">:</span> <span class="string">&quot;YYYY-MM-dd&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;partition.duration.ms&quot;</span><span class="punctuation">:</span> <span class="string">&quot;100&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;locale&quot;</span><span class="punctuation">:</span> <span class="string">&quot;CHINA&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;timezone&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Asia/Shanghai&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>


<p>上传配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -X POST -H <span class="string">&quot;Content-Type: application/json&quot;</span> --data @hdfs-t1.json http://node1:8083/connectors</span></span><br></pre></td></tr></table></figure>

<p>查看hdfs文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs dfs -ls /tmp/confluent/test3/topics/t3</span><br><span class="line">Found 1 items</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2018-12-07 12:01 /tmp/confluent/test3/topics/t3/2018-12-07</span><br><span class="line"></span><br><span class="line">$ hdfs dfs -ls /tmp/confluent/test3/topics/t3/2018-12-07</span><br><span class="line">Found 4 items</span><br><span class="line">-rw-r--r--   3 root supergroup         45 2018-12-07 12:01 /tmp/confluent/test3/topics/t3/2018-12-07/t3+0+0000000000+0000000000.json</span><br><span class="line">-rw-r--r--   3 root supergroup         46 2018-12-07 12:01 /tmp/confluent/test3/topics/t3/2018-12-07/t3+1+0000000000+0000000000.json</span><br><span class="line">-rw-r--r--   3 root supergroup         44 2018-12-07 12:01 /tmp/confluent/test3/topics/t3/2018-12-07/t3+1+0000000001+0000000001.json</span><br><span class="line">-rw-r--r--   3 root supergroup         45 2018-12-07 12:01 /tmp/confluent/test3/topics/t3/2018-12-07/t3+2+0000000000+0000000000.json</span><br></pre></td></tr></table></figure>



<h3 id="按多个字段归类存放"><a href="#按多个字段归类存放" class="headerlink" title="按多个字段归类存放"></a>按多个字段归类存放</h3><p>配置文件<code>hdfs-f2.json</code></p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfs-sink-f2&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;connector.class&quot;</span><span class="punctuation">:</span> <span class="string">&quot;io.confluent.connect.hdfs.HdfsSinkConnector&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tasks.max&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;topics&quot;</span><span class="punctuation">:</span> <span class="string">&quot;t1&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;hdfs.url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfs://mycentos:9000/f2&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;flush.size&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;format.class&quot;</span><span class="punctuation">:</span> <span class="string">&quot;io.confluent.connect.hdfs.json.JsonFormat&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;partitioner.class&quot;</span><span class="punctuation">:</span> <span class="string">&quot;io.confluent.connect.storage.partitioner.FieldPartitioner&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;partition.field.name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;f1,f2&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>提取字段需要传入的数据类型为avro,所以需要启动<code>schema-registry</code>服务，并通过<code>kafka-avro-console-producer</code>来创建数据。</p>
<p>如果是通过<code>confluent start</code>命令，该服务会在本节点自动启动，否则需要手动启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果是confluent start会启动该服务，否则需要手动启动</span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">&#123;CONFLUENT_HOME&#125;/bin/schema-registry-start -daemon <span class="variable">$&#123;CONFLUENT_HOME&#125;</span>/etc/schema-registry/schema-registry.properties</span></span><br></pre></td></tr></table></figure>
<p>配置文件schem-registry.properties需要做如下修改</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 不同的节点设置不同的域名，如node2就设置为http://node2:8081</span><br><span class="line">listeners=http://node1:8081</span><br><span class="line"></span><br><span class="line">kafkastore.connection.url=node1:2181,node2:2181,node3:2181</span><br></pre></td></tr></table></figure>

<p>每个节点都需要分别配置并启动。</p>
<p>准备数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/kafka-avro-console-producer --broker-list node1:9092 --topic t1 \</span></span><br><span class="line"><span class="language-bash">--property value.schema=<span class="string">&#x27;&#123;&quot;type&quot;:&quot;record&quot;,&quot;name&quot;:&quot;myrecord&quot;,&quot;fields&quot;:[&#123;&quot;name&quot;:&quot;f1&quot;,&quot;type&quot;:&quot;string&quot;&#125;,&#123;&quot;name&quot;:&quot;f2&quot;,&quot;type&quot;:&quot;string&quot;&#125;,&#123;&quot;name&quot;:&quot;f3&quot;,&quot;type&quot;:&quot;string&quot;&#125;]&#125;&#x27;</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&#123;<span class="string">&quot;f1&quot;</span>:<span class="string">&quot;type1&quot;</span>,<span class="string">&quot;f2&quot;</span>:<span class="string">&quot;2332&quot;</span>,<span class="string">&quot;f3&quot;</span>:<span class="string">&quot;sadf 12124&quot;</span>&#125;</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&#123;<span class="string">&quot;f1&quot;</span>:<span class="string">&quot;type1&quot;</span>,<span class="string">&quot;f2&quot;</span>:<span class="string">&quot;2333&quot;</span>,<span class="string">&quot;f3&quot;</span>:<span class="string">&quot;sadf 123124&quot;</span>&#125;</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&#123;<span class="string">&quot;f1&quot;</span>:<span class="string">&quot;type2&quot;</span>,<span class="string">&quot;f2&quot;</span>:<span class="string">&quot;2333&quot;</span>,<span class="string">&quot;f3&quot;</span>:<span class="string">&quot;sadf 12324&quot;</span>&#125;</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&#123;<span class="string">&quot;f1&quot;</span>:<span class="string">&quot;type3&quot;</span>,<span class="string">&quot;f2&quot;</span>:<span class="string">&quot;2334&quot;</span>,<span class="string">&quot;f3&quot;</span>:<span class="string">&quot;sadf 1231&quot;</span>&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>上传hdfs-connector 配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -X POST -H <span class="string">&quot;Content-Type: application/json&quot;</span> --data @hdfs-f2.json http://node1:8083/connectors</span></span><br></pre></td></tr></table></figure>



<p>查看hdfs文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hdfs dfs -<span class="built_in">ls</span> /f2/topics/t1</span></span><br><span class="line">Found 3 items</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2018-12-10 12:12 /f2/topics/t1/f1=type1</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2018-12-10 12:12 /f2/topics/t1/f1=type2</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2018-12-10 12:12 /f2/topics/t1/f1=type3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">hdfs dfs -<span class="built_in">ls</span> /f2/topics/t1/f1=type1</span></span><br><span class="line">Found 2 items</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2018-12-10 12:12 /f2/topics/t1/f1=type1/f2=2332</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2018-12-10 12:12 /f2/topics/t1/f1=type1/f2=2333</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<blockquote>
<p>提问：存放的格式为<code>/f1=type1/f2=2332</code>,有没有办法改成<code>/type1/2332</code>呢？</p>
<p>UPD:<a target="_blank" rel="noopener" href="https://github.com/confluentinc/kafka-connect-hdfs/issues/397">https://github.com/confluentinc/kafka-connect-hdfs/issues/397</a></p>
<p>太长不看：暂时不考虑支持这种做法</p>
</blockquote>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a target="_blank" rel="noopener" href="https://docs.confluent.io/current/connect/kafka-connect-hdfs/index.html">Kafka Connect HDFS</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.confluent.io/current/connect/kafka-connect-hdfs/configuration_options.html#hdfs">HDFS Connector Configuration Options</a></li>
</ol>
</div><div class="post-copyright"><script type="text/javascript" src="/blog/js/copyright.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/blog/css/copyright.css"><p><span>版权声明：</span><p>除另有声明外，本博客文章均采用 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/"><b>知识共享(Creative Commons) 署名-非商业性使用-相同方式共享 3.0 中国大陆许可协议</b></a> 进行许可。</p></p></div><br><script type="text/javascript" src="/blog/js/share.js?v=1.0.0" async></script><a class="article-share-link" data-url="https://counter2015.github.io/blog/2018/12/15/Kafka%20HDFS%20Sink%20Connector%20%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/" data-id="cl1f5m0ti0003hupv13kn17li" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAQ4AAAEOCAAAAABd2qZ5AAAD30lEQVR42u3aW47jMAwEwLn/pWcPkLXdTcrYLFD5GjhOJJUHYPj4+Ylfvx+vz+tXV+6/4fOe/f2f7x5+4cCBAweO8qj3h7zf4tV274+R7Of+s/lDejgFDhw4cOA4xJFv+v7+9s5ZgEyY8p3gwIEDB47v4Zgdo00ONwEbBw4cOHB8P0f7qbZIt0necODAgQPH93BsSnJ5+tSG0jbxa9/FgQMHDhxvcOTB7//9+5X5Dhw4cODAEYeufdCdBc52z23Z8eF0OHDgwIFjzTEbINhsfdOaahPI2WAEDhw4cODYcJxqHeVNnU05Ly8U5t8w7L/hwIEDB46AY9+S2TR+2lBajykk6R8OHDhw4DjKMVs+CXLtFmdpWBuGoxQOBw4cOHCMOJKttwHyFMosSA8TPxw4cODAcZRjc2VzvT18XsQshhhw4MCBA8dRjk2q1jZ42tLeb/zKByaijBYHDhw4cIw4ZgFpc0+b1LWsRVi9WgsHDhw4cLzMkYfANj1rE7xZETN5FwcOHDhwnOKYhcxNYta2jtrCX7ti9H+BAwcOHDgWzac3wl7eKEpSrE36l5wOBw4cOHBsONoAmWwxH24onthiaC9Hx4EDBw4cb3DkYa8t1c2GDPKj5qtcnhoHDhw4cKw52jG12UBbm1btH0yO9bAKDhw4cOAYcbSNpVOpYP53+0jakuJDrRQHDhw4cMQcZ0cZNgE1Sf+SYNkmeNH/BQ4cOHDgGKVwbXGtbfbMCoWnkr02/cOBAwcOHHuO5GNtCMyh89GHfZtqRYkDBw4cOAKO5Kb8njYtPPWpfWERBw4cOHCc4shD7Nn785Jf+z1v/BTAgQMHDhw5x6YsOBtf2AfCNmAXWDhw4MCB4xBHsq22dDgbU5g1hGaDdJfFQRw4cODAsZ4o2IS6ZIFZ+6odd0vCbfRzAQcOHDhwjDjaxWYtqDz1akNye/3hThw4cODAseZIgtamaJgfu/3+WdGwbkrhwIEDB44XONpj7Bs/bSNqf2wcOHDgwHGKIx8CSFKjTdqWhM926K0O9jhw4MCB4xBHO6wwG3doxxRm6LMkEAcOHDhwnOLIU6a8eJcMFswKjnuUaG84cODAgWPBsWkX7euRbeJXPOHgG/6yKxw4cODAseaYhb3Z6EBeEMyD66ykuPlJgQMHDhw4Eo5ZW2hvPDtku586gcSBAwcOHIc4kiVPpW3trpIEcvYwcODAgQPHN3BsDrMfestLhDMmHDhw4MDxrzj24w7tCMIMtH4wOHDgwIHjEEfbQGqZkpJiO0gxW/chGOPAgQMHjjXHqpQWHHiGkhx+s9YmQcWBAwcOHBccfwBfjLnMEWKKewAAAABJRU5ErkJggg==">分享</a><div class="tags"><a href="/blog/tagskafka"><i class="fa fa-tag">kafka</i></a><a href="/blog/tagshadoop"><i class="fa fa-tag">hadoop</i></a></div><div class="post-nav"><a class="pre" href="/blog/2019/01/05/scalatra1/">Scalatra in Action 1. hello, world</a><a class="next" href="/blog/2018/12/02/Kafka%20File%20Connector%20%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/">Kafka File Connector 简单使用</a></div><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/sukkaw/disqusjs/dist/disqusjs.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/sukkaw/disqusjs/dist/disqus.js"></script><script type="text/javascript" id="disqus-count-script">$(function() {
  var xhr = new XMLHttpRequest();
  xhr.open('GET', '//disqus.com/next/config.json', true);
  xhr.timeout = 2500;
  xhr.onreadystatechange = function () {
    if (xhr.readyState === 4 && xhr.status === 200) {
      $('.post-meta .post-comments-count').show();
      var s = document.createElement('script');
      s.id = 'dsq-count-scr';
      s.src = 'https://counter2015.disqus.com/count.js';
      s.async = true;
      (document.head || document.body).appendChild(s);
    }
  };
  xhr.ontimeout = function () { xhr.abort(); };
  xhr.send(null);
});
</script><div class="comments" id="disqus_thread"><script type="text/javascript">// Load comments with DisqusJS
function loadComments() {
  window.dsqjs = new DisqusJS({
    shortname: 'counter2015',
    siteName: 'Not determined yet',
    identifier: '2018/12/15/Kafka HDFS Sink Connector 简单使用/',
    url: 'https://counter2015.github.io/blog/2018/12/15/Kafka HDFS Sink Connector 简单使用/',
    title: 'Kafka HDFS Sink Connector 简单使用',
    api: '',
    apikey: '',
    admin: '',
    adminLabel: ''
  });
}
// Lazy load {# Credit: https://github.com/theme-next/hexo-theme-next/blob/master/layout/_third-party/comments/disqus.swig #}
(function () {
  var offsetTop = document.getElementById('disqus_thread').offsetTop - window.innerHeight;
  if (offsetTop <= 0) {
    // Load directly when there's no scrollbar
    window.addEventListener('load', loadComments, false);
  } else {
    var disqusScroll = function () {
      // offsetTop may changes because of manually resizing browser window or lazy loading images
      var offsetTop = document.getElementById('disqus_thread').offsetTop - window.innerHeight;
      var scrollTop = window.scrollY;

      // Pre-load comments a bit? (margin or anything else)
      if (offsetTop - scrollTop < 60) {
        window.removeEventListener('scroll', disqusScroll);
        loadComments();
      }
    };
    window.addEventListener('scroll', disqusScroll);
  }
})();
// Scroll to comments automatically if #comment-xxx anchor specified
window.addEventListener('load', function () {
  // I don't know why, it just works.
  window.setTimeout(function () {
    if (location.hash.indexOf('#comment-') !== -1) {
      document.getElementById('disqus_thread').scrollIntoView(true);
    }
  }, 100);
}, false);
</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://counter2015.github.io/blog"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/blog/categories/puzzles/">puzzles</a></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/%E5%85%B6%E4%BB%96/">其他</a></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/%E6%8A%80%E6%9C%AF/">技术</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/blog/tags/%E5%A4%87%E5%BF%98/" style="font-size: 15px;">备忘</a> <a href="/blog/tags/redis/" style="font-size: 15px;">redis</a> <a href="/blog/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/blog/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/blog/tags/hbase/" style="font-size: 15px;">hbase</a> <a href="/blog/tags/%E4%BC%9A%E8%AE%AE/" style="font-size: 15px;">会议</a> <a href="/blog/tags/%E6%9D%82%E8%B0%88/" style="font-size: 15px;">杂谈</a> <a href="/blog/tags/scala/" style="font-size: 15px;">scala</a> <a href="/blog/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" style="font-size: 15px;">读书笔记</a> <a href="/blog/tags/Scalatra/" style="font-size: 15px;">Scalatra</a> <a href="/blog/tags/zookeeper/" style="font-size: 15px;">zookeeper</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/blog/2019/04/07/puzzle5/">Scala Puzzle 5.The Missing List</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/04/05/scalatra4/">Scalatra in Action 4. 处理用户输入</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/04/05/baiduopen7th/">百度技术开放日7th</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/03/24/puzzle4/">Scala Puzzle 4.Now You See Me, Now You Don't</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/03/23/scalatra3/">Scalatra in Action 3. 你要去哪里？</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/03/23/hbase/">hbase安装指南</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/03/10/RedisLive/">Redis Live部署备忘</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/03/10/kafka-manager/">kafka manager简单部署备忘</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/03/09/name-theroy/">命名杂谈</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/02/23/puzzle3/">Scala Puzzle 3.Location, Location, Location</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> 最近评论</i></div><script type="text/javascript" src="//counter2015.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://wiki.hushhw.cn" title="hushhw's blog 身经百战见得多了" target="_blank">hushhw's blog 身经百战见得多了</a><ul></ul><a href="https://blog.iseki.space" title="isekiのNote" target="_blank">isekiのNote</a><ul></ul><a href="https://razertory.github.io" title="Razetory的技术博客" target="_blank">Razetory的技术博客</a><ul></ul><a href="https://blog.ajin.cloud" title="ajin的博客" target="_blank">ajin的博客</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2022 <a href="/blog/." rel="nofollow">Not determined yet.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/blog/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/blog/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><script type="text/javascript" src="/blog/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/blog/css/copycode.css"><script type="text/javascript" src="/blog/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/blog/js/smartresize.js?v=1.0.0"></script></div></body></html>